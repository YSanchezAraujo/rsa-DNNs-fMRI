{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.cuda\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from proj_utils import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: \n",
    "\n",
    "### Packaging important meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part 1 informatin:\n",
      " {'nframes': 35655, 'nmins': 23.47, 'nsecs': 1408.1999999999998, 'tr': 1.5, 'ntr': 946, 'frames_per_sec': 25.319556881124843, 'frames_per_tr': 37.979335321687266}\n",
      "\n",
      "part 2 information:\n",
      " {'nframes': 38870, 'nmins': 25.55, 'nsecs': 1533.0, 'tr': 1.5, 'ntr': 1030, 'frames_per_sec': 25.355512067840834, 'frames_per_tr': 38.03326810176125}\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR1 = (\n",
    "    \"/media/yoel/second_ssd/neu502b/\"\n",
    "    \"sherlock_mv4_png/sherlock_part1_pngs\"\n",
    ")\n",
    "\n",
    "DATA_DIR2 = (\n",
    "    \"/media/yoel/second_ssd/neu502b/\"\n",
    "    \"sherlock_mv4_png/sherlock_part2_pngs\"\n",
    ")\n",
    "\n",
    "PART1_INFO = {}\n",
    "PART2_INFO = {}\n",
    "\n",
    "files1 = [os.path.join(DATA_DIR1, x) for x in os.listdir(DATA_DIR1) if x.endswith(\".png\")]\n",
    "files2 = [os.path.join(DATA_DIR2, x) for x in os.listdir(DATA_DIR2) if x.endswith(\".png\")]\n",
    "\n",
    "PART1_INFO[\"nframes\"] = len(files1)\n",
    "PART1_INFO[\"nmins\"] = 23.47\n",
    "PART1_INFO[\"nsecs\"] = PART1_INFO[\"nmins\"] * 60\n",
    "PART1_INFO[\"tr\"] = 1.5\n",
    "PART1_INFO[\"ntr\"] = 946\n",
    "PART1_INFO[\"frames_per_sec\"] = PART1_INFO[\"nframes\"] / PART1_INFO[\"nsecs\"]\n",
    "PART1_INFO[\"frames_per_tr\"] = PART1_INFO[\"frames_per_sec\"] * 0.5 + PART1_INFO[\"frames_per_sec\"]\n",
    "\n",
    "PART2_INFO[\"nframes\"] = len(files2)\n",
    "PART2_INFO[\"nmins\"] = 25.55\n",
    "PART2_INFO[\"nsecs\"] = PART2_INFO[\"nmins\"] * 60\n",
    "PART2_INFO[\"tr\"] = 1.5\n",
    "PART2_INFO[\"ntr\"] = 1030\n",
    "PART2_INFO[\"frames_per_sec\"] = PART2_INFO[\"nframes\"] / PART2_INFO[\"nsecs\"]\n",
    "PART2_INFO[\"frames_per_tr\"] = PART2_INFO[\"frames_per_sec\"] * 0.5 + PART2_INFO[\"frames_per_sec\"]\n",
    "\n",
    "print(\"part 1 informatin:\\n\", PART1_INFO)\n",
    "\n",
    "print(\"\\npart 2 information:\\n\", PART2_INFO)\n",
    "\n",
    "# sort each file list by the frame number\n",
    "files1 = list(sort_files(files1))\n",
    "files2 = list(sort_files(files2))\n",
    "\n",
    "# these should match the nframes so we will assert that\n",
    "assert int(files1[-1].split(\"_\")[-1].split(\".\")[0]) == PART1_INFO[\"nframes\"]\n",
    "assert int(files2[-1].split(\"_\")[-1].split(\".\")[0]) == PART2_INFO[\"nframes\"]\n",
    "\n",
    "BATCH_SIZE = 37\n",
    "LAYERS = (1, 4, 7, 9, 11)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: \n",
    "\n",
    "### As seen above about 38 frames correspond to a one TR. We want to compute the activations for each relevant layer of alexnet, for each of the 38 frames in the TR. Then we average those activations across the frame dimension.\n",
    "\n",
    "TODO:\n",
    "\n",
    "    [ ] create a window within each batch to truncate the frames within the TR: reduced autocorrelation\n",
    "  \n",
    "    [ ] compute average activations using this truncated window\n",
    "  \n",
    "    [ ] write the saved activations to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this takes around 4 and a half minutes\n",
    "with torch.no_grad():\n",
    "    alexnet = models.alexnet(pretrained=True).eval().to(device)\n",
    "    batch_vals = {}\n",
    "\n",
    "    for idx, batch in enumerate(gen_batch(range(PART1_INFO[\"nframes\"]), BATCH_SIZE)):\n",
    "        batch_vals[f\"batch_{idx}\"] = {l:0 for l in LAYERS}\n",
    "        \n",
    "        # iterating over all ~ 37 - 38 frames\n",
    "        for frame_index in batch:\n",
    "            img = process_img(files1[frame_index], unsqueeze=True)\n",
    "            activations = all_acts(img.to(device), alexnet)\n",
    "            \n",
    "            # computing mean resursively to save on array space\n",
    "            for key in activations.keys():\n",
    "                batch_vals[f\"batch_{idx}\"][key] += (\n",
    "                    1/(frame_index+1) * (activations[key] - batch_vals[f\"batch_{idx}\"][key])\n",
    "            )\n",
    "                \n",
    "        # move arrays from GPU to cpu to wherever it is usually stored (on the heap?)\n",
    "        for key in activations.keys():\n",
    "            batch_vals[f\"batch_{idx}\"][key] = batch_vals[f\"batch_{idx}\"][key].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "964"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_vals.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
